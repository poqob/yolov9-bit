[34m[1mtrain_dual: [0mweights=, cfg=models/detect/yolov9-e.yaml, data=data/dataset.yaml, hyp=hyp.scratch-high.yaml, epochs=4, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov9-e, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest
YOLO üöÄ 32a30ad Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce GTX 1650, 3719MiB)

[34m[1mhyperparameters: [0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3
[34m[1mClearML: [0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO üöÄ in ClearML
[34m[1mComet: [0mrun 'pip install comet_ml' to automatically track and visualize YOLO üöÄ runs in Comet
[34m[1mTensorBoard: [0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/
Overriding model.yaml nc=80 with nc=6

                 from  n    params  module                                  arguments                     
  0                -1  1         0  models.common.Silence                   []                            
  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 
  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  3                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        
  4                -1  1    164352  models.common.ADown                     [256, 256]                    
  5                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       
  6                -1  1    656384  models.common.ADown                     [512, 512]                    
  7                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      
  8                -1  1   2623488  models.common.ADown                     [1024, 1024]                  
  9                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     
 10                 1  1      4160  models.common.CBLinear                  [64, [64]]                    
 11                 3  1     49344  models.common.CBLinear                  [256, [64, 128]]              
 12                 5  1    229824  models.common.CBLinear                  [512, [64, 128, 256]]         
 13                 7  1    984000  models.common.CBLinear                  [1024, [64, 128, 256, 512]]   
 14                 9  1   2033600  models.common.CBLinear                  [1024, [64, 128, 256, 512, 1024]]
 15                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]                 
 16[10, 11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[0, 0, 0, 0, 0]]             
 17                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
 18[11, 12, 13, 14, -1]  1         0  models.common.CBFuse                    [[1, 1, 1, 1]]                
 19                -1  1    252160  models.common.RepNCSPELAN4              [128, 256, 128, 64, 2]        
 20                -1  1    164352  models.common.ADown                     [256, 256]                    
 21  [12, 13, 14, -1]  1         0  models.common.CBFuse                    [[2, 2, 2]]                   
 22                -1  1   1004032  models.common.RepNCSPELAN4              [256, 512, 256, 128, 2]       
 23                -1  1    656384  models.common.ADown                     [512, 512]                    
 24      [13, 14, -1]  1         0  models.common.CBFuse                    [[3, 3]]                      
 25                -1  1   4006912  models.common.RepNCSPELAN4              [512, 1024, 512, 256, 2]      
 26                -1  1   2623488  models.common.ADown                     [1024, 1024]                  
 27          [14, -1]  1         0  models.common.CBFuse                    [[4]]                         
 28                -1  1   4269056  models.common.RepNCSPELAN4              [1024, 1024, 512, 256, 2]     
 29                 9  1    787968  models.common.SPPELAN                   [1024, 512, 256]              
 30                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 31           [-1, 7]  1         0  models.common.Concat                    [1]                           
 32                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      
 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 34           [-1, 5]  1         0  models.common.Concat                    [1]                           
 35                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      
 36                28  1    787968  models.common.SPPELAN                   [1024, 512, 256]              
 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 38          [-1, 25]  1         0  models.common.Concat                    [1]                           
 39                -1  1   4005888  models.common.RepNCSPELAN4              [1536, 512, 512, 256, 2]      
 40                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 41          [-1, 22]  1         0  models.common.Concat                    [1]                           
 42                -1  1   1069056  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 2]      
 43                -1  1    164352  models.common.ADown                     [256, 256]                    
 44          [-1, 39]  1         0  models.common.Concat                    [1]                           
 45                -1  1   3612672  models.common.RepNCSPELAN4              [768, 512, 512, 256, 2]       
 46                -1  1    656384  models.common.ADown                     [512, 512]                    
 47          [-1, 36]  1         0  models.common.Concat                    [1]                           
 48                -1  1  12860416  models.common.RepNCSPELAN4              [1024, 512, 1024, 512, 2]     
 49[35, 32, 29, 42, 45, 48]  1  10990532  models.yolo.DualDDetect                 [6, [256, 512, 512, 256, 512, 512]]
yolov9-e summary: 1476 layers, 69415556 parameters, 69415524 gradients, 244.9 GFLOPs

[34m[1mAMP: [0mchecks passed ‚úÖ
[34m[1moptimizer:[0m SGD(lr=0.01) with parameter groups 356 weight(decay=0.0), 375 weight(decay=0.0005), 373 bias
[34m[1malbumentations: [0m1 validation error for InitSchema
size
  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...'mask_interpolation': 0}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
[34m[1mtrain: [0mScanning /mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/data/train.cache... 162 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 00:00[34m[1mtrain: [0mScanning /mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/data/train.cache... 162 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 00:00
[34m[1mval: [0mScanning /mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/data/val.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 00:00[34m[1mval: [0mScanning /mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/data/val.cache... 34 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 00:00
[34m[1mval: [0mWARNING ‚ö†Ô∏è /mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/data/val/182.png: 1 duplicate labels removed
Plotting labels to runs/train/yolov9-e/labels.jpg... 
/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/train_dual.py:255: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=amp)
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mruns/train/yolov9-e[0m
Starting training for 4 epochs...

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
  0%|          | 0/21 00:00/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/train_dual.py:313: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(amp):
  0%|          | 0/21 00:01
Traceback (most recent call last):
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/train_dual.py", line 644, in <module>
    main(opt)
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/train_dual.py", line 538, in main
    train(opt.hyp, opt, device, callbacks)
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/train_dual.py", line 314, in train
    pred = model(imgs)  # forward
           ^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/yolo.py", line 633, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/yolo.py", line 533, in _forward_once
    x = m(x)  # run
        ^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/common.py", line 676, in forward
    y.extend((m(y[-1])) for m in [self.cv2, self.cv3])
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/common.py", line 676, in <genexpr>
    y.extend((m(y[-1])) for m in [self.cv2, self.cv3])
              ^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/common.py", line 447, in forward
    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))
                                      ^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/models/common.py", line 117, in forward
    return self.act(self.bn(self.conv(x)))
                            ^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/newdisk/dosyalar/Dosyalar/projeler/py/EKG-1005-TUBITAK/venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.63 GiB of which 3.88 MiB is free. Including non-PyTorch memory, this process has 3.62 GiB memory in use. Of the allocated memory 3.48 GiB is allocated by PyTorch, and 83.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
